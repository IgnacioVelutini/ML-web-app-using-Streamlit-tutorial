{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import re\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Load your dataset\n",
                "file_path = '../data/raw/iphone.csv'  # Adjust to your local path\n",
                "iphone_reviews = pd.read_csv(file_path)\n",
                "\n",
                "# Clean text (remove special characters, make lowercase)\n",
                "def clean_text(text):\n",
                "    text = re.sub(r'[^A-Za-z\\s]', '', str(text))  # Remove non-alphabet characters\n",
                "    return text.lower()\n",
                "\n",
                "# Apply cleaning to review descriptions\n",
                "iphone_reviews['reviewDescription'] = iphone_reviews['reviewDescription'].fillna('')\n",
                "iphone_reviews['cleaned_review'] = iphone_reviews['reviewDescription'].apply(clean_text)\n",
                "\n",
                "# Create sentiment labels based on ratingScore\n",
                "def label_sentiment(rating):\n",
                "    if rating <= 2:\n",
                "        return 'negative'\n",
                "    elif rating == 3:\n",
                "        return 'neutral'\n",
                "    else:\n",
                "        return 'positive'\n",
                "\n",
                "iphone_reviews['sentiment'] = iphone_reviews['ratingScore'].apply(label_sentiment)\n",
                "\n",
                "# Split the data into training and test sets\n",
                "X = iphone_reviews['cleaned_review']\n",
                "y = iphone_reviews['sentiment']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "# Initialize TF-IDF Vectorizer\n",
                "vectorizer = TfidfVectorizer(max_features=5000)\n",
                "\n",
                "# Fit and transform the training data, and transform the test data\n",
                "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
                "X_test_tfidf = vectorizer.transform(X_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logistic Regression Performance:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.70      0.62      0.66       130\n",
                        "     neutral       1.00      0.04      0.07        53\n",
                        "    positive       0.84      0.97      0.90       430\n",
                        "\n",
                        "    accuracy                           0.81       613\n",
                        "   macro avg       0.85      0.54      0.54       613\n",
                        "weighted avg       0.82      0.81      0.78       613\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "# Train Logistic Regression model\n",
                "logreg = LogisticRegression(max_iter=1000)\n",
                "logreg.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions and evaluate\n",
                "y_pred_logreg = logreg.predict(X_test_tfidf)\n",
                "print(\"Logistic Regression Performance:\")\n",
                "print(classification_report(y_test, y_pred_logreg))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Naive Bayes Performance:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.89      0.25      0.40       130\n",
                        "     neutral       0.00      0.00      0.00        53\n",
                        "    positive       0.74      0.99      0.85       430\n",
                        "\n",
                        "    accuracy                           0.75       613\n",
                        "   macro avg       0.54      0.42      0.41       613\n",
                        "weighted avg       0.71      0.75      0.68       613\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
                        "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
                        "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.naive_bayes import MultinomialNB\n",
                "\n",
                "# Train Naive Bayes model\n",
                "nb = MultinomialNB()\n",
                "nb.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions and evaluate\n",
                "y_pred_nb = nb.predict(X_test_tfidf)\n",
                "print(\"Naive Bayes Performance:\")\n",
                "print(classification_report(y_test, y_pred_nb))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "SVM Performance:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.74      0.62      0.68       130\n",
                        "     neutral       1.00      0.13      0.23        53\n",
                        "    positive       0.84      0.97      0.90       430\n",
                        "\n",
                        "    accuracy                           0.82       613\n",
                        "   macro avg       0.86      0.57      0.60       613\n",
                        "weighted avg       0.83      0.82      0.80       613\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.svm import SVC\n",
                "\n",
                "# Train SVM model\n",
                "svm = SVC()\n",
                "svm.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions and evaluate\n",
                "y_pred_svm = svm.predict(X_test_tfidf)\n",
                "print(\"SVM Performance:\")\n",
                "print(classification_report(y_test, y_pred_svm))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Random Forest Performance:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.74      0.52      0.61       130\n",
                        "     neutral       0.92      0.21      0.34        53\n",
                        "    positive       0.82      0.97      0.89       430\n",
                        "\n",
                        "    accuracy                           0.81       613\n",
                        "   macro avg       0.83      0.57      0.61       613\n",
                        "weighted avg       0.81      0.81      0.78       613\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "# Initialize and train the Random Forest model\n",
                "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions and evaluate\n",
                "y_pred_rf = rf.predict(X_test_tfidf)\n",
                "print(\"Random Forest Performance:\")\n",
                "print(classification_report(y_test, y_pred_rf))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logistic Regression Accuracy: 0.8140\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.70      0.62      0.66       130\n",
                        "     neutral       1.00      0.04      0.07        53\n",
                        "    positive       0.84      0.97      0.90       430\n",
                        "\n",
                        "    accuracy                           0.81       613\n",
                        "   macro avg       0.85      0.54      0.54       613\n",
                        "weighted avg       0.82      0.81      0.78       613\n",
                        "\n",
                        "Naive Bayes Accuracy: 0.7504\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.89      0.25      0.40       130\n",
                        "     neutral       0.00      0.00      0.00        53\n",
                        "    positive       0.74      0.99      0.85       430\n",
                        "\n",
                        "    accuracy                           0.75       613\n",
                        "   macro avg       0.54      0.42      0.41       613\n",
                        "weighted avg       0.71      0.75      0.68       613\n",
                        "\n",
                        "SVM Accuracy: 0.8238\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.74      0.62      0.68       130\n",
                        "     neutral       1.00      0.13      0.23        53\n",
                        "    positive       0.84      0.97      0.90       430\n",
                        "\n",
                        "    accuracy                           0.82       613\n",
                        "   macro avg       0.86      0.57      0.60       613\n",
                        "weighted avg       0.83      0.82      0.80       613\n",
                        "\n",
                        "Random Forest Accuracy: 0.8108\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.74      0.52      0.61       130\n",
                        "     neutral       0.92      0.21      0.34        53\n",
                        "    positive       0.82      0.97      0.89       430\n",
                        "\n",
                        "    accuracy                           0.81       613\n",
                        "   macro avg       0.83      0.57      0.61       613\n",
                        "weighted avg       0.81      0.81      0.78       613\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
                        "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
                        "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
                        "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
                    ]
                }
            ],
            "source": [
                "# Collect model performance results for comparison\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "models = {\n",
                "    'Logistic Regression': logreg,\n",
                "    'Naive Bayes': nb,\n",
                "    'SVM': svm,\n",
                "    'Random Forest': rf\n",
                "}\n",
                "\n",
                "# Evaluate and print accuracy of each model\n",
                "for name, model in models.items():\n",
                "    y_pred = model.predict(X_test_tfidf)\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
                "    print(classification_report(y_test, y_pred))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
                        "Best Parameters:  {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
                        "Tuned SVM Performance:\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "    negative       0.74      0.71      0.72       130\n",
                        "     neutral       0.92      0.21      0.34        53\n",
                        "    positive       0.87      0.97      0.92       430\n",
                        "\n",
                        "    accuracy                           0.85       613\n",
                        "   macro avg       0.84      0.63      0.66       613\n",
                        "weighted avg       0.85      0.85      0.83       613\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.svm import SVC\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "# Define a parameter grid to search through\n",
                "param_grid = {\n",
                "    'C': [0.1, 1, 10, 100],  # Penalty parameter\n",
                "    'kernel': ['linear', 'rbf'],  # Linear and Radial Basis Function kernels\n",
                "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
                "}\n",
                "\n",
                "# Set up the GridSearchCV to find the best combination of hyperparameters\n",
                "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1)\n",
                "\n",
                "# Fit the grid search model\n",
                "grid_search.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Print the best hyperparameters found\n",
                "print(\"Best Parameters: \", grid_search.best_params_)\n",
                "\n",
                "# Evaluate the tuned model\n",
                "y_pred_svm_tuned = grid_search.best_estimator_.predict(X_test_tfidf)\n",
                "print(\"Tuned SVM Performance:\")\n",
                "print(classification_report(y_test, y_pred_svm_tuned))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = TfidfVectorizer(ngram_range=(1, 2))  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "svm = SVC(class_weight='balanced')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dataset Characteristics:\n",
                "\n",
                "The dataset consists of iPhone reviews from Amazon, with three sentiment classes: positive, neutral, and negative.\n",
                "The reviews are largely skewed towards the positive class (with most ratings being 4 or 5 stars), while neutral and negative reviews are relatively fewer in number.\n",
                "This class imbalance presents a challenge, especially for predicting neutral sentiment, which the model struggles with.\n",
                "Model Performance:\n",
                "\n",
                "After tuning the SVM model using a radial basis function (RBF) kernel, the overall accuracy improved to 85%. This indicates that the model is quite effective at classifying the reviews into the appropriate sentiment categories.\n",
                "The model performs exceptionally well in predicting positive sentiment, achieving a high F1-score of 0.92 and recall of 0.97.\n",
                "Predictions for negative sentiment also improved, with a reasonable F1-score of 0.72. However, thereâ€™s still room to enhance recall, suggesting that some negative reviews may not be correctly identified.\n",
                "The neutral sentiment is where the model performs weakest, with an F1-score of 0.34. This is likely due to the class imbalance and the inherent difficulty in distinguishing neutral reviews from either positive or negative ones.\n",
                "Model Implications:\n",
                "\n",
                "The model is highly effective for classifying positive reviews, making it suitable for applications that prioritize identifying strong customer satisfaction.\n",
                "It performs moderately well in detecting negative reviews, which could still be useful for flagging potentially dissatisfied customers. However, improvements in recall could ensure that more negative reviews are caught.\n",
                "The inability to accurately detect neutral sentiment means that the model may struggle to identify mixed or balanced feedback, where users may express both pros and cons. In real-world applications, this could lead to an overemphasis on extreme sentiments (positive or negative).\n",
                "Use Case Applications:\n",
                "\n",
                "Customer Feedback Analysis: The model is well-suited for analyzing customer feedback at scale, particularly for identifying highly satisfied or dissatisfied customers.\n",
                "Market Insights: Companies can use the model to understand the distribution of sentiment in product reviews, helping them gauge product reception and improve areas of concern based on negative reviews.\n",
                "Customer Service Prioritization: Businesses could use the model to prioritize handling negative reviews quickly, while understanding that neutral feedback may require further refinement in the model to be detected accurately."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
