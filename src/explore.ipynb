{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import re\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Load your dataset\n",
                "file_path = '../data/raw/iphone.csv'  # Adjust to your local path\n",
                "iphone_reviews = pd.read_csv(file_path)\n",
                "\n",
                "# Clean text (remove special characters, make lowercase)\n",
                "def clean_text(text):\n",
                "    text = re.sub(r'[^A-Za-z\\s]', '', str(text))  # Remove non-alphabet characters\n",
                "    return text.lower()\n",
                "\n",
                "# Apply cleaning to review descriptions\n",
                "iphone_reviews['reviewDescription'] = iphone_reviews['reviewDescription'].fillna('')\n",
                "iphone_reviews['cleaned_review'] = iphone_reviews['reviewDescription'].apply(clean_text)\n",
                "\n",
                "# Create sentiment labels based on ratingScore\n",
                "def label_sentiment(rating):\n",
                "    if rating <= 2:\n",
                "        return 'negative'\n",
                "    elif rating == 3:\n",
                "        return 'neutral'\n",
                "    else:\n",
                "        return 'positive'\n",
                "\n",
                "iphone_reviews['sentiment'] = iphone_reviews['ratingScore'].apply(label_sentiment)\n",
                "\n",
                "# Split the data into training and test sets\n",
                "X = iphone_reviews['cleaned_review']\n",
                "y = iphone_reviews['sentiment']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "# Initialize TF-IDF Vectorizer\n",
                "vectorizer = TfidfVectorizer(max_features=5000)\n",
                "\n",
                "# Fit and transform the training data, and transform the test data\n",
                "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
                "X_test_tfidf = vectorizer.transform(X_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "# Train Logistic Regression model\n",
                "logreg = LogisticRegression(max_iter=1000)\n",
                "logreg.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions and evaluate\n",
                "y_pred_logreg = logreg.predict(X_test_tfidf)\n",
                "print(\"Logistic Regression Performance:\")\n",
                "print(classification_report(y_test, y_pred_logreg))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.naive_bayes import MultinomialNB\n",
                "\n",
                "# Train Naive Bayes model\n",
                "nb = MultinomialNB()\n",
                "nb.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions and evaluate\n",
                "y_pred_nb = nb.predict(X_test_tfidf)\n",
                "print(\"Naive Bayes Performance:\")\n",
                "print(classification_report(y_test, y_pred_nb))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.svm import SVC\n",
                "\n",
                "# Train SVM model\n",
                "svm = SVC()\n",
                "svm.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions and evaluate\n",
                "y_pred_svm = svm.predict(X_test_tfidf)\n",
                "print(\"SVM Performance:\")\n",
                "print(classification_report(y_test, y_pred_svm))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "# Initialize and train the Random Forest model\n",
                "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Make predictions and evaluate\n",
                "y_pred_rf = rf.predict(X_test_tfidf)\n",
                "print(\"Random Forest Performance:\")\n",
                "print(classification_report(y_test, y_pred_rf))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect model performance results for comparison\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "models = {\n",
                "    'Logistic Regression': logreg,\n",
                "    'Naive Bayes': nb,\n",
                "    'SVM': svm,\n",
                "    'Random Forest': rf\n",
                "}\n",
                "\n",
                "# Evaluate and print accuracy of each model\n",
                "for name, model in models.items():\n",
                "    y_pred = model.predict(X_test_tfidf)\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
                "    print(classification_report(y_test, y_pred))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.svm import SVC\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "# Define a parameter grid to search through\n",
                "param_grid = {\n",
                "    'C': [0.1, 1, 10, 100],  # Penalty parameter\n",
                "    'kernel': ['linear', 'rbf'],  # Linear and Radial Basis Function kernels\n",
                "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
                "}\n",
                "\n",
                "# Set up the GridSearchCV to find the best combination of hyperparameters\n",
                "grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', verbose=1)\n",
                "\n",
                "# Fit the grid search model\n",
                "grid_search.fit(X_train_tfidf, y_train)\n",
                "\n",
                "# Print the best hyperparameters found\n",
                "print(\"Best Parameters: \", grid_search.best_params_)\n",
                "\n",
                "# Evaluate the tuned model\n",
                "y_pred_svm_tuned = grid_search.best_estimator_.predict(X_test_tfidf)\n",
                "print(\"Tuned SVM Performance:\")\n",
                "print(classification_report(y_test, y_pred_svm_tuned))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = TfidfVectorizer(ngram_range=(1, 2))  \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "svm = SVC(class_weight='balanced')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Dataset Characteristics:\n",
                "\n",
                "The dataset consists of iPhone reviews from Amazon, with three sentiment classes: positive, neutral, and negative.\n",
                "The reviews are largely skewed towards the positive class (with most ratings being 4 or 5 stars), while neutral and negative reviews are relatively fewer in number.\n",
                "This class imbalance presents a challenge, especially for predicting neutral sentiment, which the model struggles with.\n",
                "Model Performance:\n",
                "\n",
                "After tuning the SVM model using a radial basis function (RBF) kernel, the overall accuracy improved to 85%. This indicates that the model is quite effective at classifying the reviews into the appropriate sentiment categories.\n",
                "The model performs exceptionally well in predicting positive sentiment, achieving a high F1-score of 0.92 and recall of 0.97.\n",
                "Predictions for negative sentiment also improved, with a reasonable F1-score of 0.72. However, thereâ€™s still room to enhance recall, suggesting that some negative reviews may not be correctly identified.\n",
                "The neutral sentiment is where the model performs weakest, with an F1-score of 0.34. This is likely due to the class imbalance and the inherent difficulty in distinguishing neutral reviews from either positive or negative ones.\n",
                "Model Implications:\n",
                "\n",
                "The model is highly effective for classifying positive reviews, making it suitable for applications that prioritize identifying strong customer satisfaction.\n",
                "It performs moderately well in detecting negative reviews, which could still be useful for flagging potentially dissatisfied customers. However, improvements in recall could ensure that more negative reviews are caught.\n",
                "The inability to accurately detect neutral sentiment means that the model may struggle to identify mixed or balanced feedback, where users may express both pros and cons. In real-world applications, this could lead to an overemphasis on extreme sentiments (positive or negative).\n",
                "Use Case Applications:\n",
                "\n",
                "Customer Feedback Analysis: The model is well-suited for analyzing customer feedback at scale, particularly for identifying highly satisfied or dissatisfied customers.\n",
                "Market Insights: Companies can use the model to understand the distribution of sentiment in product reviews, helping them gauge product reception and improve areas of concern based on negative reviews.\n",
                "Customer Service Prioritization: Businesses could use the model to prioritize handling negative reviews quickly, while understanding that neutral feedback may require further refinement in the model to be detected accurately."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "# Save the model regression\n",
                "model_filename = '../models/logistic_regression_model.pkl'\n",
                "with open(model_filename, 'wb') as file:\n",
                "    pickle.dump(model, file)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the vectorizer \n",
                "vectorizer_filename = '../models/tfidf_vectorizer.pkl'\n",
                "with open(vectorizer_filename, 'wb') as file:\n",
                "    pickle.dump(vectorizer, file)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import streamlit as st\n",
                "import pickle\n",
                "\n",
                "# Load the saved model and vectorizer from ../models/\n",
                "model = pickle.load(open('../models/logistic_regression_model.pkl', 'rb'))\n",
                "vectorizer = pickle.load(open('../models/tfidf_vectorizer.pkl', 'rb'))\n",
                "\n",
                "st.title('Sentiment Analysis App')\n",
                "\n",
                "# Input field for the user to enter text\n",
                "user_input = st.text_area(\"Enter a review\")\n",
                "\n",
                "if st.button('Predict'):\n",
                "    if user_input:\n",
                "        # Transform the input text using the vectorizer\n",
                "        transformed_input = vectorizer.transform([user_input])\n",
                "        # Predict the sentiment\n",
                "        prediction = model.predict(transformed_input)\n",
                "        st.write(f'The predicted sentiment is: {prediction[0]}')\n",
                "    else:\n",
                "        st.write(\"Please enter a review to analyze.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from dotenv import load_dotenv\n",
                "import os\n",
                "from sqlalchemy import create_engine\n",
                "\n",
                "# Load environment variables from .env file\n",
                "load_dotenv()\n",
                "\n",
                "# Get the DATABASE_URL from the environment\n",
                "database_url = os.getenv('DATABASE_URL')\n",
                "\n",
                "# Connect to the PostgreSQL database\n",
                "engine = create_engine(database_url)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from sqlalchemy import create_engine\n",
                "\n",
                "# Get the DATABASE_URL from environment variables\n",
                "database_url = os.getenv('DATABASE_URL')\n",
                "\n",
                "# Create the SQLAlchemy engine for connecting to PostgreSQL\n",
                "if database_url:\n",
                "    engine = create_engine(database_url)\n",
                "\n",
                "    try:\n",
                "        connection = engine.connect()\n",
                "        print(\"Connection to PostgreSQL successful!\")\n",
                "        connection.close()\n",
                "    except Exception as e:\n",
                "        print(f\"Error connecting to the database: {e}\")\n",
                "else:\n",
                "    print(\"DATABASE_URL environment variable not set.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
